{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>AI FUNDAMENTALS BOOTCAMP - MODULE II</center>\n",
    "## <center>ML TEMPLATE</center>\n",
    "\n",
    "\n",
    "### Project Description\n",
    "A description of the project that you would like to give\n",
    "\n",
    "### Project Objective\n",
    "In your own words\n",
    "\n",
    "### Data Source Description\n",
    "Decribe the datasource(s) used in this template\n",
    "\n",
    "\n",
    "## **<center>Scoring Guidelines - Module II</center>**\n",
    "\n",
    "### **Phase 1. Data Summary: 10% - 1 point** <br>\n",
    "- In this phase, you must import all the necessary libraries for working with data (e.g., pandas, numpy, nltk, etc.) and load the Titanic dataset into a pandas DataFrame. Ensure the data loads correctly and perform an initial visualization (e.g., display the first rows using head() or verify the dimensions).<br>\n",
    "\n",
    "### **Phase 2. EDA (Univariate and Multivariate Analysis) and Understanding Columns Data Processing: 30% - 3 points** <br>\n",
    "- Explore the dataset to understand its structure and content. Analyze the distributions of the dataset variables. This phase helps you understand the data and prepare a strategy to process and use it in predictive analysis. <br>\n",
    "\n",
    "### **Phase 3. Data Preprocessing: 40% - 4 points** <br>\n",
    "- Clean and transform the selected text columns. This step transforms the text data into useful information that machine learning algorithms can process. <br>\n",
    "\n",
    "### **Phase 4. Conclusion: 10% - 1 points**<br>\n",
    "- Summary of the understanding of the application of various preprocessing, vectorization, and model performance on the dataset. This conclusion should contain key points from the data scientist's perspective to the user/client who needs to make a decision based on the analysis being performed. <br>\n",
    "\n",
    "### **Phase 5. Notebook Presentation: 10% - 10 points** <br>\n",
    "- Notebook structure and flow\n",
    "- Well-commented code\n",
    "\n",
    "### Each phase should contain its respective observations, as these will be part of the evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 1. Data Summary: 10% - 1 point**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries needed to develop the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "#######################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graficos\n",
    "#######################################\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# Configuracion matplotlib\n",
    "#######################################\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# to display values upto 2 decimal places\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n",
    "# Removes the limit for the number of displayed columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Sets the limit for the number of displayed rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "# Instruction from https://seaborn.pydata.org/generated/seaborn.countplot.html\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and descriptive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\"../data/2.Titanic-Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of numeric columns\n",
    "titanic_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive analysis of all columns in the dataset\n",
    "titanic_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for unique values for all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.agg(['nunique']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking how many NaN or null values are present in each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.Cabin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing all columns of all data types\n",
    "columnas = [col for col in titanic_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columnas:\n",
    "    print(\"\\n\", titanic_df[col].value_counts(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing columns of data type 'object'\n",
    "columnas_object = [col for col in titanic_df.columns if titanic_df[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columnas_object:\n",
    "    print(\"\\n\", titanic_df[col].value_counts(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining if there are duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the standard deviation of columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing columns of data type 'object'\n",
    "columnas_numericos = [col for col in titanic_df.columns if titanic_df[col].dtype != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columnas_numericos:\n",
    "    print(\"\\n\",col,\": \",titanic_df[col].skew().sum(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information counting if you do not want to do it completely for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.Sex.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sex_conteo = titanic_df.Sex.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sex_conteo *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.Figure(figsize=(12,8))\n",
    "sns.barplot(x=col_sex_conteo.index,y=col_sex_conteo.values,palette='viridis')\n",
    "plt.title('Contedo de la columna SEX')\n",
    "plt.xlabel('Genero')\n",
    "plt.ylabel('Procentaje')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.Survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sobreviviente_conteo_sin_normalizar = titanic_df.Survived.value_counts()\n",
    "col_sobreviviente_conteo_normalizado = titanic_df.Survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sobreviviente_conteo_normalizado *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.Figure(figsize=(12,8))\n",
    "sns.barplot(x=col_sobreviviente_conteo_sin_normalizar.index,y=col_sobreviviente_conteo_sin_normalizar.values,palette='viridis')\n",
    "plt.title('Conteo de la columna Survived')\n",
    "plt.xlabel('Genero')\n",
    "plt.ylabel('Total')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.Figure(figsize=(12,8))\n",
    "sns.barplot(x=col_sobreviviente_conteo_normalizado.index,y=col_sobreviviente_conteo_normalizado.values,palette='viridis')\n",
    "plt.title('Datos normalizados de la columna Survived')\n",
    "plt.xlabel('Genero')\n",
    "plt.ylabel('Porcentaje')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 2. EDA (Univariate and Multivariate Analysis) and Understanding Columns Data Processing: 30% - 3 points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calculating the interquartile range (Q3 (75%) - Q1 (25%))*\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "The line called the median allows me to have equal shares of the data in the dataset.\n",
    "\n",
    "Calculating the lower and upper limits of the boxplot graph\n",
    "- Lower limit = Q1 - 1.5 x IQR\n",
    "- Upper limit = Q3 + 1.5 x IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to show the density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"mediumturquoise\"\n",
    "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
    "\n",
    "    if bins:\n",
    "        sns.histplot(\n",
    "            data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, color=\"mediumpurple\"\n",
    "        )\n",
    "    else:\n",
    "        sns.histplot(\n",
    "            data=data, x=feature, kde=kde, ax=ax_hist2, color=\"mediumpurple\"\n",
    "        )  # For histogram\n",
    "\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Fare Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(titanic_df,\"Fare\", kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Age Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_boxplot(titanic_df,\"Age\", kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the function that allows me to generate bar charts with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeled_barplot(data, feature, perc=False, n=None):\n",
    "    \"\"\"\n",
    "    Barplot with percentage at the top\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    perc: whether to display percentages instead of count (default is False)\n",
    "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(data[feature])  # length of the column\n",
    "    count = data[feature].nunique()\n",
    "    if n is None:\n",
    "        plt.figure(figsize=(count + 1, 5))\n",
    "    else:\n",
    "        plt.figure(figsize=(n + 1, 5))\n",
    "\n",
    "    plt.xticks(rotation=90, fontsize=15)\n",
    "    ax = sns.countplot(\n",
    "        data=data,\n",
    "        x=feature,\n",
    "        palette=\"Paired\",\n",
    "        order=data[feature].value_counts().index[:n].sort_values(),\n",
    "    )\n",
    "\n",
    "    for p in ax.patches:\n",
    "        if perc == True:\n",
    "            label = \"{:.1f}%\".format(\n",
    "                100 * p.get_height() / total\n",
    "            )  # percentage of each class of the category\n",
    "        else:\n",
    "            label = p.get_height()  # count of each level of the category\n",
    "\n",
    "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
    "        y = p.get_height()  # height of the plot\n",
    "\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            (x, y),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            size=12,\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )  # annotate the percentage\n",
    "\n",
    "    plt.show()  # show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(titanic_df,\"Survived\", perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(titanic_df,\"Pclass\", perc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_barplot(titanic_df,\"Sex\", perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Phase 3. Data Preprocessing: 40% - 4 points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Age'] = titanic_df['Age'].fillna(titanic_df['Age'].median())\n",
    "titanic_df['Embarked'] = titanic_df['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripcion de columnas numericas\n",
    "titanic_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis desciptivo de todas las columnas del dataset\n",
    "titanic_df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis desciptivo de todas las columnas del dataset\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.get_dummies(titanic_df, columns=['Sex', 'Embarked'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tssdev (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
